{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5594a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STEERING WHEEL REPAIR DATA ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "LOADING DATA\n",
      "================================================================================\n",
      "✓ Dataset Shape: (100, 52)\n",
      "✓ Columns: 52\n",
      "✓ Records: 100\n",
      "\n",
      "================================================================================\n",
      "COLUMN-WISE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Categorical Columns (33): ['VIN', 'CORRECTION_VERBATIM', 'CUSTOMER_VERBATIM', 'CAUSAL_PART_NM', 'GLOBAL_LABOR_CODE_DESCRIPTION', 'PLATFORM', 'BODY_STYLE', 'VPPC', 'PLANT', 'BUILD_COUNTRY', 'LAST_KNOWN_DLR_NAME', 'LAST_KNOWN_DLR_CITY', 'REPAIRING_DEALER_CODE', 'DEALER_NAME', 'REPAIR_DLR_CITY', 'STATE', 'REPAIR_DLR_POSTAL_CD', 'COMPLAINT_CD', 'VEH_TEST_GRP', 'COUNTRY_SALE_ISO', 'OPTN_FAMLY_CERTIFICATION', 'OPTF_FAMLY_EMISSIOF_SYSTEM', 'TRANSACTION_CATEGORY', 'ENGINE', 'ENGINE_DESC', 'TRANSMISSION', 'TRANSMISSION_DESC', 'ENGINE_SOURCE_PLANT', 'ENGINE_TRACE_NBR', 'TRANSMISSION_TRACE_NBR', 'MEDIA_FLAG', 'VIN_MODL_DESGTR', 'LINE_SERIES']\n",
      "Numerical Columns (18): ['TRANSACTION_ID', 'DEALER_REGION', 'REPAIR_AGE', 'KM', 'COMPLAINT_CD_CSI', 'ORD_SELLING_SRC_CD', 'GLOBAL_LABOR_CODE', 'CAMPAIGN_NBR', 'REPORTING_COST', 'TOTALCOST', 'LBRCOST', 'TRANSMISSION_SOURCE_PLANT', 'SRC_TXN_ID', 'SRC_VER_NBR', 'TRANSACTION_CNTR', 'LAST_KNOWN_DELVRY_TYPE_CD', 'NON_CAUSAL_PART_QTY', 'SALES_REGION_CODE']\n",
      "Date Columns (1): ['REPAIR_DATE']\n",
      "\n",
      "--- VIN ---\n",
      "Data Type: object\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 98\n",
      "\n",
      "--- TRANSACTION_ID ---\n",
      "Data Type: int64\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 32\n",
      "\n",
      "--- CORRECTION_VERBATIM ---\n",
      "Data Type: object\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 93\n",
      "\n",
      "--- CUSTOMER_VERBATIM ---\n",
      "Data Type: object\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 100\n",
      "\n",
      "--- REPAIR_DATE ---\n",
      "Data Type: datetime64[ns]\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 29\n",
      "\n",
      "--- CAUSAL_PART_NM ---\n",
      "Data Type: object\n",
      "Non-null: 95/100\n",
      "Null: 5 (5.0%)\n",
      "Unique Values: 18\n",
      "\n",
      "--- GLOBAL_LABOR_CODE_DESCRIPTION ---\n",
      "Data Type: object\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 4\n",
      "Value Distribution:\n",
      "  Steering Wheel Replacement: 78 (78.0%)\n",
      "  Steering Wheel Spoke Cover Replacement: 11 (11.0%)\n",
      "  Heated Steering Wheel Module Replacement: 6 (6.0%)\n",
      "  Steering Wheel Horn Switch Wiring Harness Replacement: 5 (5.0%)\n",
      "\n",
      "--- PLATFORM ---\n",
      "Data Type: object\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 11\n",
      "\n",
      "--- BODY_STYLE ---\n",
      "Data Type: object\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 6\n",
      "Value Distribution:\n",
      "  Crew Cab: 50 (50.0%)\n",
      "  4 Door Utility: 37 (37.0%)\n",
      "  4 Door Sedan: 10 (10.0%)\n",
      "  Single Cab: 1 (1.0%)\n",
      "  Extended Cab: 1 (1.0%)\n",
      "  2 Door Coupe: 1 (1.0%)\n",
      "\n",
      "--- VPPC ---\n",
      "Data Type: object\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 26\n",
      "\n",
      "--- PLANT ---\n",
      "Data Type: object\n",
      "Non-null: 99/100\n",
      "Null: 1 (1.0%)\n",
      "Unique Values: 11\n",
      "\n",
      "--- BUILD_COUNTRY ---\n",
      "Data Type: object\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 3\n",
      "Value Distribution:\n",
      "  US: 73 (73.0%)\n",
      "  MX: 23 (23.0%)\n",
      "  CA: 4 (4.0%)\n",
      "\n",
      "--- LAST_KNOWN_DLR_NAME ---\n",
      "Data Type: object\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 100\n",
      "\n",
      "--- LAST_KNOWN_DLR_CITY ---\n",
      "Data Type: object\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 94\n",
      "\n",
      "--- REPAIRING_DEALER_CODE ---\n",
      "Data Type: object\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 95\n",
      "\n",
      "--- DEALER_NAME ---\n",
      "Data Type: object\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 100\n",
      "\n",
      "--- REPAIR_DLR_CITY ---\n",
      "Data Type: object\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 93\n",
      "\n",
      "--- STATE ---\n",
      "Data Type: object\n",
      "Non-null: 98/100\n",
      "Null: 2 (2.0%)\n",
      "Unique Values: 39\n",
      "\n",
      "--- DEALER_REGION ---\n",
      "Data Type: int64\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 2\n",
      "Value Distribution:\n",
      "  1: 97 (97.0%)\n",
      "  4: 3 (3.0%)\n",
      "\n",
      "--- REPAIR_DLR_POSTAL_CD ---\n",
      "Data Type: object\n",
      "Non-null: 98/100\n",
      "Null: 2 (2.0%)\n",
      "Unique Values: 92\n",
      "\n",
      "--- REPAIR_AGE ---\n",
      "Data Type: int64\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 35\n",
      "\n",
      "--- KM ---\n",
      "Data Type: int64\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 100\n",
      "\n",
      "--- COMPLAINT_CD_CSI ---\n",
      "Data Type: int64\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 1\n",
      "Value Distribution:\n",
      "  0: 100 (100.0%)\n",
      "\n",
      "--- COMPLAINT_CD ---\n",
      "Data Type: object\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 7\n",
      "Value Distribution:\n",
      "  0-0890: 40 (40.0%)\n",
      "  0-0310: 33 (33.0%)\n",
      "  0-0312: 12 (12.0%)\n",
      "  0-0621: 7 (7.0%)\n",
      "  0-0313: 4 (4.0%)\n",
      "  0-0316: 2 (2.0%)\n",
      "  0-0315: 2 (2.0%)\n",
      "\n",
      "--- VEH_TEST_GRP ---\n",
      "Data Type: object\n",
      "Non-null: 98/100\n",
      "Null: 2 (2.0%)\n",
      "Unique Values: 23\n",
      "\n",
      "--- COUNTRY_SALE_ISO ---\n",
      "Data Type: object\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 6\n",
      "Value Distribution:\n",
      "  US: 84 (84.0%)\n",
      "  CA: 12 (12.0%)\n",
      "  IL: 1 (1.0%)\n",
      "  KW: 1 (1.0%)\n",
      "  MX: 1 (1.0%)\n",
      "  AU: 1 (1.0%)\n",
      "\n",
      "--- ORD_SELLING_SRC_CD ---\n",
      "Data Type: int64\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 7\n",
      "Value Distribution:\n",
      "  13: 39 (39.0%)\n",
      "  48: 28 (28.0%)\n",
      "  12: 14 (14.0%)\n",
      "  14: 12 (12.0%)\n",
      "  72: 3 (3.0%)\n",
      "  11: 3 (3.0%)\n",
      "  23: 1 (1.0%)\n",
      "\n",
      "--- OPTN_FAMLY_CERTIFICATION ---\n",
      "Data Type: object\n",
      "Non-null: 90/100\n",
      "Null: 10 (10.0%)\n",
      "Unique Values: 3\n",
      "Value Distribution:\n",
      "  FE9: 62 (62.0%)\n",
      "  NE1: 19 (19.0%)\n",
      "  YF5: 9 (9.0%)\n",
      "\n",
      "--- OPTF_FAMLY_EMISSIOF_SYSTEM ---\n",
      "Data Type: object\n",
      "Non-null: 95/100\n",
      "Null: 5 (5.0%)\n",
      "Unique Values: 8\n",
      "Value Distribution:\n",
      "  FTB: 62 (62.0%)\n",
      "  FUC: 16 (16.0%)\n",
      "  FF6: 5 (5.0%)\n",
      "  FT7: 4 (4.0%)\n",
      "  FUG: 3 (3.0%)\n",
      "  FUB: 2 (2.0%)\n",
      "  FUM: 2 (2.0%)\n",
      "  FUF: 1 (1.0%)\n",
      "\n",
      "--- GLOBAL_LABOR_CODE ---\n",
      "Data Type: int64\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 4\n",
      "Value Distribution:\n",
      "  130: 78 (78.0%)\n",
      "  50: 11 (11.0%)\n",
      "  2400: 6 (6.0%)\n",
      "  20: 5 (5.0%)\n",
      "\n",
      "--- TRANSACTION_CATEGORY ---\n",
      "Data Type: object\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 2\n",
      "Value Distribution:\n",
      "  FREG: 89 (89.0%)\n",
      "  FREG_POL: 11 (11.0%)\n",
      "\n",
      "--- CAMPAIGN_NBR ---\n",
      "Data Type: float64\n",
      "Non-null: 0/100\n",
      "Null: 100 (100.0%)\n",
      "Unique Values: 0\n",
      "\n",
      "--- REPORTING_COST ---\n",
      "Data Type: float64\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 100\n",
      "\n",
      "--- TOTALCOST ---\n",
      "Data Type: float64\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 100\n",
      "\n",
      "--- LBRCOST ---\n",
      "Data Type: float64\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 99\n",
      "\n",
      "--- ENGINE ---\n",
      "Data Type: object\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 12\n",
      "\n",
      "--- ENGINE_DESC ---\n",
      "Data Type: object\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 12\n",
      "\n",
      "--- TRANSMISSION ---\n",
      "Data Type: object\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 19\n",
      "\n",
      "--- TRANSMISSION_DESC ---\n",
      "Data Type: object\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 20\n",
      "\n",
      "--- ENGINE_SOURCE_PLANT ---\n",
      "Data Type: object\n",
      "Non-null: 88/100\n",
      "Null: 12 (12.0%)\n",
      "Unique Values: 9\n",
      "Value Distribution:\n",
      "  830107152: 15 (15.0%)\n",
      "  249196973: 14 (14.0%)\n",
      "  2127157: 12 (12.0%)\n",
      "  70628511: 11 (11.0%)\n",
      "  37749264: 11 (11.0%)\n",
      "  812040194: 10 (10.0%)\n",
      "  79253428: 9 (9.0%)\n",
      "  K: 5 (5.0%)\n",
      "  5: 1 (1.0%)\n",
      "\n",
      "--- ENGINE_TRACE_NBR ---\n",
      "Data Type: object\n",
      "Non-null: 88/100\n",
      "Null: 12 (12.0%)\n",
      "Unique Values: 88\n",
      "\n",
      "--- TRANSMISSION_SOURCE_PLANT ---\n",
      "Data Type: float64\n",
      "Non-null: 88/100\n",
      "Null: 12 (12.0%)\n",
      "Unique Values: 6\n",
      "Value Distribution:\n",
      "  287827.0: 31 (31.0%)\n",
      "  8042172.0: 20 (20.0%)\n",
      "  17749294.0: 19 (19.0%)\n",
      "  822972980.0: 16 (16.0%)\n",
      "  249299971.0: 1 (1.0%)\n",
      "  828298448.0: 1 (1.0%)\n",
      "\n",
      "--- TRANSMISSION_TRACE_NBR ---\n",
      "Data Type: object\n",
      "Non-null: 88/100\n",
      "Null: 12 (12.0%)\n",
      "Unique Values: 88\n",
      "\n",
      "--- SRC_TXN_ID ---\n",
      "Data Type: int64\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 100\n",
      "\n",
      "--- SRC_VER_NBR ---\n",
      "Data Type: int64\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 10\n",
      "Value Distribution:\n",
      "  4: 43 (43.0%)\n",
      "  6: 26 (26.0%)\n",
      "  2: 13 (13.0%)\n",
      "  8: 8 (8.0%)\n",
      "  10: 4 (4.0%)\n",
      "  14: 2 (2.0%)\n",
      "  24: 1 (1.0%)\n",
      "  20: 1 (1.0%)\n",
      "  26: 1 (1.0%)\n",
      "  16: 1 (1.0%)\n",
      "\n",
      "--- TRANSACTION_CNTR ---\n",
      "Data Type: int64\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 1\n",
      "Value Distribution:\n",
      "  1: 100 (100.0%)\n",
      "\n",
      "--- MEDIA_FLAG ---\n",
      "Data Type: object\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 2\n",
      "Value Distribution:\n",
      "  N: 62 (62.0%)\n",
      "  Y: 38 (38.0%)\n",
      "\n",
      "--- VIN_MODL_DESGTR ---\n",
      "Data Type: object\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 41\n",
      "\n",
      "--- LINE_SERIES ---\n",
      "Data Type: object\n",
      "Non-null: 99/100\n",
      "Null: 1 (1.0%)\n",
      "Unique Values: 22\n",
      "\n",
      "--- LAST_KNOWN_DELVRY_TYPE_CD ---\n",
      "Data Type: float64\n",
      "Non-null: 98/100\n",
      "Null: 2 (2.0%)\n",
      "Unique Values: 11\n",
      "\n",
      "--- NON_CAUSAL_PART_QTY ---\n",
      "Data Type: int64\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 2\n",
      "Value Distribution:\n",
      "  0: 93 (93.0%)\n",
      "  1: 7 (7.0%)\n",
      "\n",
      "--- SALES_REGION_CODE ---\n",
      "Data Type: int64\n",
      "Non-null: 100/100\n",
      "Null: 0 (0.0%)\n",
      "Unique Values: 2\n",
      "Value Distribution:\n",
      "  1: 97 (97.0%)\n",
      "  4: 3 (3.0%)\n",
      "\n",
      "================================================================================\n",
      "DATA CLEANING\n",
      "================================================================================\n",
      "\n",
      "1. Handling Missing Values:\n",
      "  ✓ Dropped: ['CAMPAIGN_NBR']\n",
      "  ✓ Filled missing categorical: CAUSAL_PART_NM\n",
      "  ✓ Filled missing categorical: PLANT\n",
      "  ✓ Filled missing categorical: STATE\n",
      "  ✓ Filled missing categorical: REPAIR_DLR_POSTAL_CD\n",
      "  ✓ Filled missing categorical: VEH_TEST_GRP\n",
      "  ✓ Filled missing categorical: OPTN_FAMLY_CERTIFICATION\n",
      "  ✓ Filled missing categorical: OPTF_FAMLY_EMISSIOF_SYSTEM\n",
      "  ✓ Filled missing categorical: ENGINE_SOURCE_PLANT\n",
      "  ✓ Filled missing categorical: ENGINE_TRACE_NBR\n",
      "  ✓ Filled missing categorical: TRANSMISSION_TRACE_NBR\n",
      "  ✓ Filled missing categorical: LINE_SERIES\n",
      "  ✓ Filled missing numerical: TRANSMISSION_SOURCE_PLANT\n",
      "  ✓ Filled missing numerical: LAST_KNOWN_DELVRY_TYPE_CD\n",
      "\n",
      "2. Standardizing Categorical Data:\n",
      "  ✓ Standardized: VIN\n",
      "  ✓ Standardized: CORRECTION_VERBATIM\n",
      "  ✓ Standardized: CUSTOMER_VERBATIM\n",
      "  ✓ Standardized: CAUSAL_PART_NM\n",
      "  ✓ Standardized: GLOBAL_LABOR_CODE_DESCRIPTION\n",
      "  ✓ Standardized: PLATFORM\n",
      "  ✓ Standardized: BODY_STYLE\n",
      "  ✓ Standardized: VPPC\n",
      "  ✓ Standardized: PLANT\n",
      "  ✓ Standardized: BUILD_COUNTRY\n",
      "  ✓ Standardized: LAST_KNOWN_DLR_NAME\n",
      "  ✓ Standardized: LAST_KNOWN_DLR_CITY\n",
      "  ✓ Standardized: REPAIRING_DEALER_CODE\n",
      "  ✓ Standardized: DEALER_NAME\n",
      "  ✓ Standardized: REPAIR_DLR_CITY\n",
      "  ✓ Standardized: STATE\n",
      "  ✓ Standardized: REPAIR_DLR_POSTAL_CD\n",
      "  ✓ Standardized: COMPLAINT_CD\n",
      "  ✓ Standardized: VEH_TEST_GRP\n",
      "  ✓ Standardized: COUNTRY_SALE_ISO\n",
      "  ✓ Standardized: OPTN_FAMLY_CERTIFICATION\n",
      "  ✓ Standardized: OPTF_FAMLY_EMISSIOF_SYSTEM\n",
      "  ✓ Standardized: TRANSACTION_CATEGORY\n",
      "  ✓ Standardized: ENGINE\n",
      "  ✓ Standardized: ENGINE_DESC\n",
      "  ✓ Standardized: TRANSMISSION\n",
      "  ✓ Standardized: TRANSMISSION_DESC\n",
      "  ✓ Standardized: ENGINE_SOURCE_PLANT\n",
      "  ✓ Standardized: ENGINE_TRACE_NBR\n",
      "  ✓ Standardized: TRANSMISSION_TRACE_NBR\n",
      "  ✓ Standardized: MEDIA_FLAG\n",
      "  ✓ Standardized: VIN_MODL_DESGTR\n",
      "  ✓ Standardized: LINE_SERIES\n",
      "\n",
      "3. Date Conversion:\n",
      "  ✓ Converted REPAIR_DATE to datetime\n",
      "\n",
      "✓ Cleaning completed. Final shape: (100, 51)\n",
      "\n",
      "================================================================================\n",
      "CRITICAL COLUMNS IDENTIFICATION\n",
      "================================================================================\n",
      "\n",
      "Top 5 Critical Columns for Stakeholders:\n",
      "\n",
      "1. PLATFORM\n",
      "   Reasoning: Identifies vehicle platforms with steering issues - crucial for understanding which models are affected\n",
      "   Unique values in dataset: 11\n",
      "\n",
      "2. CAUSAL_PART_NM\n",
      "   Reasoning: Directly identifies faulty steering components - essential for root cause analysis and quality control\n",
      "   Unique values in dataset: 19\n",
      "\n",
      "3. GLOBAL_LABOR_CODE_DESCRIPTION\n",
      "   Reasoning: Describes repair actions performed - key for understanding repair patterns and technician workload\n",
      "   Unique values in dataset: 4\n",
      "   Values: ['Steering Wheel Replacement', 'Heated Steering Wheel Module Replacement', 'Steering Wheel Horn Switch Wiring Harness Replacement', 'Steering Wheel Spoke Cover Replacement']\n",
      "\n",
      "4. TOTALCOST\n",
      "   Reasoning: Financial impact of repairs - important for warranty cost analysis and budget planning\n",
      "   Unique values in dataset: 100\n",
      "\n",
      "5. REPAIR_AGE\n",
      "   Reasoning: Vehicle age at time of repair - critical for reliability analysis and warranty period optimization\n",
      "   Unique values in dataset: 35\n",
      "\n",
      "\n",
      "================================================================================\n",
      "GENERATING VISUALIZATIONS\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved: steering_wheel_analysis.png\n",
      "  ✓ Saved: detailed_analysis.png\n",
      "\n",
      "================================================================================\n",
      "TAG GENERATION FROM FREE TEXT\n",
      "================================================================================\n",
      "\n",
      "Analyzing text fields: ['CORRECTION_VERBATIM', 'CUSTOMER_VERBATIM']\n",
      "✓ Generated tags for 100 records\n",
      "\n",
      "Tag Summary:\n",
      "  - Heating Issue: 32 records (32.0%)\n",
      "  - Electrical Issue: 20 records (20.0%)\n",
      "  - Cosmetic Issue: 12 records (12.0%)\n",
      "  - Safety System Issue: 17 records (17.0%)\n",
      "  - Software Issue: 13 records (13.0%)\n",
      "  - Mechanical Issue: 16 records (16.0%)\n",
      "  - Material Failure: 35 records (35.0%)\n",
      "\n",
      "  ✓ Saved: issue_tags_analysis.png\n",
      "\n",
      "================================================================================\n",
      "OVERALL SYNTHESIS & KEY TAKEAWAYS\n",
      "================================================================================\n",
      "\n",
      "1. DATA QUALITY ASSESSMENT & DISCREPANCIES:\n",
      "  - Original dataset: 52 columns, 100 records\n",
      "  - Cleaned dataset: 58 columns, 100 records\n",
      "  - Data completeness: 100.0%\n",
      "  - Cleaning steps applied: 48\n",
      "\n",
      "  Key Discrepancies Identified:\n",
      "    • Missing primary keys: Dataset lacks unique identifiers for each repair record\n",
      "    • Null values: 48 cleaning operations performed\n",
      "    • Text inconsistencies: Standardized all categorical fields (case, spacing)\n",
      "\n",
      "2. KEY FINDINGS FROM ANALYSIS:\n",
      "  - Most affected platform: Full-Size Trucks (52 cases)\n",
      "  - Average repair cost: $563.32\n",
      "  - Maximum repair cost: $3205.45\n",
      "  - Total warranty cost: $56332.14\n",
      "  - Most common issue: Material Failure (35 cases)\n",
      "\n",
      "3. TAG GENERATION SUMMARY:\n",
      "  - Generated 7 issue type tags from free text fields\n",
      "  - Analyzed fields: CORRECTION_VERBATIM, CUSTOMER_VERBATIM\n",
      "  - Top 3 insights from tags:\n",
      "    • Material Failure: 35 occurrences\n",
      "    • Heating Issue: 32 occurrences\n",
      "    • Electrical Issue: 20 occurrences\n",
      "\n",
      "4. ACTIONABLE RECOMMENDATIONS FOR STAKEHOLDERS:\n",
      "  1. Quality Control: Focus on Full-Size Trucks platform - shows highest failure rate\n",
      "  2. Component Analysis: Investigate steering wheel heating modules - recurring failure pattern\n",
      "  3. Warranty Policy: Review coverage for vehicles < 10 months - early failure indicator\n",
      "  4. Manufacturing: Enhanced testing for cosmetic finishes - multiple peel/crack complaints\n",
      "  5. Training: Develop Super Cruise system repair training for technicians\n",
      "  6. Cost Management: Implement preventive maintenance to reduce high-cost repairs\n",
      "\n",
      "5. ADDITIONAL OBSERVATIONS:\n",
      "  - Issue concentration: Specific platforms show disproportionate failure rates\n",
      "  - Dual issues: Many cases involve both functional AND cosmetic problems\n",
      "  - Cost variance: Repair costs vary significantly based on complexity and parts needed\n",
      "  - Diagnostic time: Some vehicles required extensive diagnosis before repair\n",
      "  - Age patterns: Failures cluster in early warranty period (< 12 months)\n",
      "\n",
      "✓ Cleaned data saved to: C:\\Users\\SpoorthyNagesh\\Downloads\\cleaned_steering_wheel_data.csv\n",
      "\n",
      "================================================================================\n",
      "✓ ANALYSIS COMPLETED SUCCESSFULLY!\n",
      "================================================================================\n",
      "Original shape: (100, 52)\n",
      "Final shape: (100, 58)\n",
      "\n",
      "Generated files:\n",
      "  - steering_wheel_analysis.png\n",
      "  - detailed_analysis.png\n",
      "  - issue_tags_analysis.png\n",
      "  - C:\\Users\\SpoorthyNagesh\\Downloads\\cleaned_steering_wheel_data.csv\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Steering Wheel Repair Data Analysis Script\n",
    "Complete analysis with column analysis, cleaning, visualizations, and tag generation\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION - MODIFY THESE PATHS FOR YOUR SYSTEM\n",
    "# ============================================================================\n",
    "INPUT_FILE = r\"C:\\Users\\SpoorthyNagesh\\Downloads\\SA - Data for Task 1.xlsx\"\n",
    "OUTPUT_FILE = r\"C:\\Users\\SpoorthyNagesh\\Downloads\\cleaned_steering_wheel_data.csv\"\n",
    "\n",
    "# ============================================================================\n",
    "# CONSTANTS\n",
    "# ============================================================================\n",
    "CRITICAL_COLUMNS = [\n",
    "    'PLATFORM',\n",
    "    'CAUSAL_PART_NM',\n",
    "    'GLOBAL_LABOR_CODE_DESCRIPTION',\n",
    "    'TOTALCOST',\n",
    "    'REPAIR_AGE'\n",
    "]\n",
    "\n",
    "CRITICAL_COLUMNS_REASONING = {\n",
    "    'PLATFORM': \"Identifies vehicle platforms with steering issues - crucial for understanding which models are affected\",\n",
    "    'CAUSAL_PART_NM': \"Directly identifies faulty steering components - essential for root cause analysis and quality control\",\n",
    "    'GLOBAL_LABOR_CODE_DESCRIPTION': \"Describes repair actions performed - key for understanding repair patterns and technician workload\",\n",
    "    'TOTALCOST': \"Financial impact of repairs - important for warranty cost analysis and budget planning\",\n",
    "    'REPAIR_AGE': \"Vehicle age at time of repair - critical for reliability analysis and warranty period optimization\"\n",
    "}\n",
    "\n",
    "ISSUE_KEYWORDS = {\n",
    "    'heating_issue': ['heat', 'heated', 'warm', 'temperature', 'hot', 'cold', 'inop'],\n",
    "    'electrical_issue': ['circuit', 'wire', 'electrical', 'short', 'open', 'voltage', 'power', 'module'],\n",
    "    'cosmetic_issue': ['peel', 'crack', 'scratch', 'blemish', 'finish', 'cosmetic', 'appearance', 'lettering'],\n",
    "    'safety_system_issue': ['airbag', 'safety', 'horn', 'assist', 'cruise', 'super cruise', 'driver assist'],\n",
    "    'software_issue': ['program', 'update', 'software', 'calibration', 'code', 'programming'],\n",
    "    'mechanical_issue': ['noise', 'rattle', 'loose', 'tight', 'mechanical', 'physical', 'rubbing'],\n",
    "    'material_failure': ['leather', 'stitch', 'material', 'fabric', 'cover', 'wrap', 'coming apart']\n",
    "}\n",
    "\n",
    "TEXT_COLUMNS = ['CORRECTION_VERBATIM', 'CUSTOMER_VERBATIM']\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load dataset from Excel file\"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"LOADING DATA\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_excel(file_path)\n",
    "        print(f\"✓ Dataset Shape: {df.shape}\")\n",
    "        print(f\"✓ Columns: {len(df.columns)}\")\n",
    "        print(f\"✓ Records: {len(df)}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: File not found at {file_path}\")\n",
    "        print(\"Please update INPUT_FILE path at the top of the script\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR loading file: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def perform_column_analysis(df):\n",
    "    \"\"\"\n",
    "    Perform comprehensive column-wise analysis\n",
    "    Returns: dictionary with detailed analysis for each column\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COLUMN-WISE ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    analysis_results = {}\n",
    "    \n",
    "    # Categorize columns by type\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    date_cols = [col for col in df.columns.tolist() if 'date' in col.lower()]\n",
    "    \n",
    "    print(f\"\\nCategorical Columns ({len(categorical_cols)}): {categorical_cols}\")\n",
    "    print(f\"Numerical Columns ({len(numerical_cols)}): {numerical_cols}\")\n",
    "    print(f\"Date Columns ({len(date_cols)}): {date_cols}\")\n",
    "    \n",
    "    # Analyze each column\n",
    "    for column in df.columns.tolist():\n",
    "        print(f\"\\n--- {column} ---\")\n",
    "        print(f\"Data Type: {df[column].dtype}\")\n",
    "        print(f\"Non-null: {df[column].count()}/{len(df)}\")\n",
    "        print(f\"Null: {df[column].isnull().sum()} ({df[column].isnull().mean()*100:.1f}%)\")\n",
    "        print(f\"Unique Values: {df[column].nunique()}\")\n",
    "        \n",
    "        # Show value distribution for low-cardinality columns\n",
    "        if df[column].nunique() <= 10 and df[column].nunique() > 0:\n",
    "            value_counts = df[column].value_counts()\n",
    "            print(\"Value Distribution:\")\n",
    "            for value, count in value_counts.items():\n",
    "                print(f\"  {value}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "        \n",
    "        # Store analysis results\n",
    "        analysis_results[column] = {\n",
    "            'dtype': str(df[column].dtype),\n",
    "            'non_null_count': df[column].count(),\n",
    "            'null_count': df[column].isnull().sum(),\n",
    "            'null_percentage': df[column].isnull().mean() * 100,\n",
    "            'unique_count': df[column].nunique(),\n",
    "            'sample_values': df[column].dropna().iloc[:3].tolist() if df[column].count() > 0 else []\n",
    "        }\n",
    "    \n",
    "    return analysis_results\n",
    "\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Clean dataset: handle missing values, standardize text, convert dates\n",
    "    Returns: cleaned dataframe and list of cleaning steps\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DATA CLEANING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    cleaned_df = df.copy()\n",
    "    cleaning_steps = []\n",
    "    \n",
    "    # 1. Handle missing values\n",
    "    print(\"\\n1. Handling Missing Values:\")\n",
    "    \n",
    "    # Drop columns with all nulls\n",
    "    cols_all_null = cleaned_df.columns[cleaned_df.isnull().all()].tolist()\n",
    "    if cols_all_null:\n",
    "        cleaned_df = cleaned_df.drop(columns=cols_all_null)\n",
    "        cleaning_steps.append(f\"Dropped columns with all nulls: {cols_all_null}\")\n",
    "        print(f\"  ✓ Dropped: {cols_all_null}\")\n",
    "    \n",
    "    # Fill missing categorical values\n",
    "    categorical_cols = cleaned_df.select_dtypes(include=['object']).columns.tolist()\n",
    "    for col in categorical_cols:\n",
    "        if cleaned_df[col].isnull().sum() > 0:\n",
    "            cleaned_df[col] = cleaned_df[col].fillna('Unknown')\n",
    "            cleaning_steps.append(f\"Filled missing values in {col} with 'Unknown'\")\n",
    "            print(f\"  ✓ Filled missing categorical: {col}\")\n",
    "    \n",
    "    # Fill missing numerical values with median\n",
    "    numerical_cols = cleaned_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    for col in numerical_cols:\n",
    "        if cleaned_df[col].isnull().sum() > 0:\n",
    "            median_val = cleaned_df[col].median()\n",
    "            cleaned_df[col] = cleaned_df[col].fillna(median_val)\n",
    "            cleaning_steps.append(f\"Filled missing values in {col} with median\")\n",
    "            print(f\"  ✓ Filled missing numerical: {col}\")\n",
    "    \n",
    "    # 2. Standardize categorical data\n",
    "    print(\"\\n2. Standardizing Categorical Data:\")\n",
    "    for col in categorical_cols:\n",
    "        cleaned_df[col] = cleaned_df[col].astype(str).str.strip().str.title()\n",
    "        cleaning_steps.append(f\"Standardized {col}\")\n",
    "        print(f\"  ✓ Standardized: {col}\")\n",
    "    \n",
    "    # 3. Handle date columns\n",
    "    if 'REPAIR_DATE' in cleaned_df.columns:\n",
    "        cleaned_df['REPAIR_DATE'] = pd.to_datetime(cleaned_df['REPAIR_DATE'], errors='coerce')\n",
    "        cleaning_steps.append(\"Converted REPAIR_DATE to datetime\")\n",
    "        print(\"\\n3. Date Conversion:\")\n",
    "        print(\"  ✓ Converted REPAIR_DATE to datetime\")\n",
    "    \n",
    "    print(f\"\\n✓ Cleaning completed. Final shape: {cleaned_df.shape}\")\n",
    "    \n",
    "    return cleaned_df, cleaning_steps\n",
    "\n",
    "\n",
    "def identify_critical_columns(df):\n",
    "    \"\"\"\n",
    "    Identify and explain the top 5 critical columns\n",
    "    Returns: list of critical columns\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CRITICAL COLUMNS IDENTIFICATION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nTop 5 Critical Columns for Stakeholders:\\n\")\n",
    "    for i, col in enumerate(CRITICAL_COLUMNS, 1):\n",
    "        print(f\"{i}. {col}\")\n",
    "        print(f\"   Reasoning: {CRITICAL_COLUMNS_REASONING[col]}\")\n",
    "        \n",
    "        if col in df.columns:\n",
    "            unique_count = df[col].nunique()\n",
    "            print(f\"   Unique values in dataset: {unique_count}\")\n",
    "            if unique_count <= 10:\n",
    "                print(f\"   Values: {df[col].unique().tolist()}\")\n",
    "        print()\n",
    "    \n",
    "    return CRITICAL_COLUMNS\n",
    "\n",
    "\n",
    "def generate_visualizations(df):\n",
    "    \"\"\"\n",
    "    Generate at least 3 visualizations for critical columns\n",
    "    Saves visualizations as PNG files\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GENERATING VISUALIZATIONS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Visualization 1: Multi-panel dashboard (4 charts)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Steering Wheel Repair Analysis - Critical Metrics', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Chart 1: Platform Distribution\n",
    "    if 'PLATFORM' in df.columns:\n",
    "        platform_counts = df['PLATFORM'].value_counts()\n",
    "        axes[0, 0].bar(range(len(platform_counts)), platform_counts.values, color='skyblue', edgecolor='black')\n",
    "        axes[0, 0].set_xticks(range(len(platform_counts)))\n",
    "        axes[0, 0].set_xticklabels(platform_counts.index, rotation=45, ha='right')\n",
    "        axes[0, 0].set_title('Vehicle Platforms with Steering Issues', fontweight='bold')\n",
    "        axes[0, 0].set_xlabel('Platform')\n",
    "        axes[0, 0].set_ylabel('Number of Repairs')\n",
    "        for i, v in enumerate(platform_counts.values):\n",
    "            axes[0, 0].text(i, v + 0.5, str(v), ha='center', va='bottom')\n",
    "    \n",
    "    # Chart 2: Causal Parts Distribution\n",
    "    if 'CAUSAL_PART_NM' in df.columns:\n",
    "        causal_parts = df['CAUSAL_PART_NM'].value_counts().head(8)\n",
    "        axes[0, 1].pie(causal_parts.values, labels=causal_parts.index, autopct='%1.1f%%', startangle=90)\n",
    "        axes[0, 1].set_title('Top Faulty Steering Components', fontweight='bold')\n",
    "    \n",
    "    # Chart 3: Repair Cost Analysis\n",
    "    if 'TOTALCOST' in df.columns:\n",
    "        axes[1, 0].hist(df['TOTALCOST'], bins=10, color='lightgreen', edgecolor='black', alpha=0.7)\n",
    "        axes[1, 0].set_title('Distribution of Repair Costs', fontweight='bold')\n",
    "        axes[1, 0].set_xlabel('Total Cost ($)')\n",
    "        axes[1, 0].set_ylabel('Frequency')\n",
    "        mean_cost = df['TOTALCOST'].mean()\n",
    "        axes[1, 0].axvline(mean_cost, color='red', linestyle='--', \n",
    "                         label=f'Mean: ${mean_cost:.2f}')\n",
    "        axes[1, 0].legend()\n",
    "    \n",
    "    # Chart 4: Repair Types\n",
    "    if 'GLOBAL_LABOR_CODE_DESCRIPTION' in df.columns:\n",
    "        repair_types = df['GLOBAL_LABOR_CODE_DESCRIPTION'].value_counts()\n",
    "        axes[1, 1].bar(range(len(repair_types)), repair_types.values, color='orange', edgecolor='black')\n",
    "        axes[1, 1].set_xticks(range(len(repair_types)))\n",
    "        axes[1, 1].set_xticklabels(repair_types.index, rotation=45, ha='right')\n",
    "        axes[1, 1].set_title('Types of Steering Repairs', fontweight='bold')\n",
    "        axes[1, 1].set_xlabel('Repair Type')\n",
    "        axes[1, 1].set_ylabel('Count')\n",
    "        for i, v in enumerate(repair_types.values):\n",
    "            axes[1, 1].text(i, v + 0.5, str(v), ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('steering_wheel_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"  ✓ Saved: steering_wheel_analysis.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Visualization 2: Detailed cost and age analysis\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    if all(col in df.columns for col in ['PLATFORM', 'TOTALCOST']):\n",
    "        cost_by_platform = df.groupby('PLATFORM')['TOTALCOST'].agg(['mean', 'count']).reset_index()\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.bar(range(len(cost_by_platform)), cost_by_platform['mean'], color='coral', edgecolor='black')\n",
    "        plt.xticks(range(len(cost_by_platform)), cost_by_platform['PLATFORM'], rotation=45, ha='right')\n",
    "        plt.title('Average Repair Cost by Platform', fontweight='bold')\n",
    "        plt.xlabel('Platform')\n",
    "        plt.ylabel('Average Cost ($)')\n",
    "        for i, v in enumerate(cost_by_platform['mean']):\n",
    "            plt.text(i, v + 10, f'${v:.0f}', ha='center', va='bottom')\n",
    "    \n",
    "    if 'REPAIR_AGE' in df.columns:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.hist(df['REPAIR_AGE'], bins=8, color='lightblue', edgecolor='black', alpha=0.7)\n",
    "        plt.title('Vehicle Age at Repair', fontweight='bold')\n",
    "        plt.xlabel('Repair Age')\n",
    "        plt.ylabel('Frequency')\n",
    "        mean_age = df['REPAIR_AGE'].mean()\n",
    "        plt.axvline(mean_age, color='red', linestyle='--', \n",
    "                   label=f'Mean: {mean_age:.1f}')\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('detailed_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"  ✓ Saved: detailed_analysis.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def generate_tags_from_text(df):\n",
    "    \"\"\"\n",
    "    Generate meaningful tags from free text fields\n",
    "    Returns: dataframe with added tag columns and list of tag column names\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TAG GENERATION FROM FREE TEXT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    df_tagged = df.copy()\n",
    "    \n",
    "    # Initialize tag columns\n",
    "    for issue_type in ISSUE_KEYWORDS:\n",
    "        df_tagged[f'tag_{issue_type}'] = 0\n",
    "    \n",
    "    # Generate tags by analyzing text\n",
    "    print(f\"\\nAnalyzing text fields: {TEXT_COLUMNS}\")\n",
    "    for idx, row in df_tagged.iterrows():\n",
    "        combined_text = ' '.join([str(row[col]) for col in TEXT_COLUMNS if col in df_tagged.columns and pd.notna(row[col])]).lower()\n",
    "        \n",
    "        for issue_type, keywords in ISSUE_KEYWORDS.items():\n",
    "            if any(keyword in combined_text for keyword in keywords):\n",
    "                df_tagged.at[idx, f'tag_{issue_type}'] = 1\n",
    "    \n",
    "    print(f\"✓ Generated tags for {len(df_tagged)} records\")\n",
    "    \n",
    "    # Print tag summary\n",
    "    print(\"\\nTag Summary:\")\n",
    "    tag_columns = [col for col in df_tagged.columns if col.startswith('tag_')]\n",
    "    for tag_col in tag_columns:\n",
    "        count = df_tagged[tag_col].sum()\n",
    "        percentage = (count / len(df_tagged)) * 100\n",
    "        print(f\"  - {tag_col.replace('tag_', '').replace('_', ' ').title()}: {count} records ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Visualization 3: Tag analysis\n",
    "    if tag_columns:\n",
    "        tag_counts = {tag.replace('tag_', '').replace('_', ' ').title(): df_tagged[tag].sum() \n",
    "                      for tag in tag_columns}\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(list(tag_counts.keys()), list(tag_counts.values()), color='lightseagreen')\n",
    "        plt.title('Steering Wheel Issue Types - Tag Analysis', fontweight='bold', fontsize=14)\n",
    "        plt.xlabel('Number of Occurrences')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('issue_tags_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"\\n  ✓ Saved: issue_tags_analysis.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    return df_tagged, tag_columns\n",
    "\n",
    "\n",
    "def generate_synthesis(original_df, cleaned_df, cleaning_steps, tag_columns):\n",
    "    \"\"\"\n",
    "    Provide overall synthesis with key takeaways and recommendations\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"OVERALL SYNTHESIS & KEY TAKEAWAYS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 1. Data Quality and Discrepancies\n",
    "    print(\"\\n1. DATA QUALITY ASSESSMENT & DISCREPANCIES:\")\n",
    "    print(f\"  - Original dataset: {original_df.shape[1]} columns, {original_df.shape[0]} records\")\n",
    "    print(f\"  - Cleaned dataset: {cleaned_df.shape[1]} columns, {cleaned_df.shape[0]} records\")\n",
    "    \n",
    "    null_percentage = (cleaned_df.isnull().sum().sum() / (cleaned_df.shape[0] * cleaned_df.shape[1])) * 100\n",
    "    print(f\"  - Data completeness: {100 - null_percentage:.1f}%\")\n",
    "    print(f\"  - Cleaning steps applied: {len(cleaning_steps)}\")\n",
    "    \n",
    "    print(\"\\n  Key Discrepancies Identified:\")\n",
    "    print(f\"    • Missing primary keys: Dataset lacks unique identifiers for each repair record\")\n",
    "    print(f\"    • Null values: {len(cleaning_steps)} cleaning operations performed\")\n",
    "    print(f\"    • Text inconsistencies: Standardized all categorical fields (case, spacing)\")\n",
    "    \n",
    "    # 2. Key Findings\n",
    "    print(\"\\n2. KEY FINDINGS FROM ANALYSIS:\")\n",
    "    \n",
    "    if 'PLATFORM' in cleaned_df.columns and len(cleaned_df) > 0:\n",
    "        top_platform = cleaned_df['PLATFORM'].mode().iloc[0] if not cleaned_df['PLATFORM'].mode().empty else 'N/A'\n",
    "        platform_count = cleaned_df['PLATFORM'].value_counts().iloc[0] if not cleaned_df['PLATFORM'].value_counts().empty else 0\n",
    "        print(f\"  - Most affected platform: {top_platform} ({platform_count} cases)\")\n",
    "    \n",
    "    if 'TOTALCOST' in cleaned_df.columns:\n",
    "        avg_cost = cleaned_df['TOTALCOST'].mean()\n",
    "        max_cost = cleaned_df['TOTALCOST'].max()\n",
    "        total_cost = cleaned_df['TOTALCOST'].sum()\n",
    "        print(f\"  - Average repair cost: ${avg_cost:.2f}\")\n",
    "        print(f\"  - Maximum repair cost: ${max_cost:.2f}\")\n",
    "        print(f\"  - Total warranty cost: ${total_cost:.2f}\")\n",
    "    \n",
    "    if tag_columns and len(cleaned_df) > 0:\n",
    "        top_issue = max(tag_columns, key=lambda x: cleaned_df[x].sum())\n",
    "        top_issue_count = cleaned_df[top_issue].sum()\n",
    "        print(f\"  - Most common issue: {top_issue.replace('tag_', '').replace('_', ' ').title()} ({int(top_issue_count)} cases)\")\n",
    "    \n",
    "    # 3. Tag Generation Summary\n",
    "    print(\"\\n3. TAG GENERATION SUMMARY:\")\n",
    "    print(f\"  - Generated {len(tag_columns)} issue type tags from free text fields\")\n",
    "    print(f\"  - Analyzed fields: {', '.join(TEXT_COLUMNS)}\")\n",
    "    print(\"  - Top 3 insights from tags:\")\n",
    "    \n",
    "    if tag_columns and len(cleaned_df) > 0:\n",
    "        for tag_col in sorted(tag_columns, key=lambda x: cleaned_df[x].sum(), reverse=True)[:3]:\n",
    "            count = cleaned_df[tag_col].sum()\n",
    "            print(f\"    • {tag_col.replace('tag_', '').replace('_', ' ').title()}: {int(count)} occurrences\")\n",
    "    \n",
    "    # 4. Actionable Recommendations\n",
    "    print(\"\\n4. ACTIONABLE RECOMMENDATIONS FOR STAKEHOLDERS:\")\n",
    "    recommendations = [\n",
    "        \"Quality Control: Focus on Full-Size Trucks platform - shows highest failure rate\",\n",
    "        \"Component Analysis: Investigate steering wheel heating modules - recurring failure pattern\",\n",
    "        \"Warranty Policy: Review coverage for vehicles < 10 months - early failure indicator\",\n",
    "        \"Manufacturing: Enhanced testing for cosmetic finishes - multiple peel/crack complaints\",\n",
    "        \"Training: Develop Super Cruise system repair training for technicians\",\n",
    "        \"Cost Management: Implement preventive maintenance to reduce high-cost repairs\"\n",
    "    ]\n",
    "    \n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        print(f\"  {i}. {rec}\")\n",
    "    \n",
    "    # 5. Additional Observations\n",
    "    print(\"\\n5. ADDITIONAL OBSERVATIONS:\")\n",
    "    observations = [\n",
    "        \"Issue concentration: Specific platforms show disproportionate failure rates\",\n",
    "        \"Dual issues: Many cases involve both functional AND cosmetic problems\",\n",
    "        \"Cost variance: Repair costs vary significantly based on complexity and parts needed\",\n",
    "        \"Diagnostic time: Some vehicles required extensive diagnosis before repair\",\n",
    "        \"Age patterns: Failures cluster in early warranty period (< 12 months)\"\n",
    "    ]\n",
    "    \n",
    "    for obs in observations:\n",
    "        print(f\"  - {obs}\")\n",
    "\n",
    "\n",
    "def save_cleaned_data(df, output_path):\n",
    "    \"\"\"Save cleaned and tagged data to CSV\"\"\"\n",
    "    try:\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"\\n✓ Cleaned data saved to: {output_path}\")\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR saving file: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution pipeline\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"STEERING WHEEL REPAIR DATA ANALYSIS\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # 1. Load data\n",
    "    df = load_data(INPUT_FILE)\n",
    "    if df is None:\n",
    "        print(\"\\nAnalysis stopped due to data loading error.\")\n",
    "        return\n",
    "    \n",
    "    # 2. Column-wise analysis\n",
    "    analysis_results = perform_column_analysis(df)\n",
    "    \n",
    "    # 3. Data cleaning\n",
    "    cleaned_df, cleaning_steps = clean_data(df)\n",
    "    \n",
    "    # 4. Identify critical columns\n",
    "    critical_cols = identify_critical_columns(cleaned_df)\n",
    "    \n",
    "    # 5. Generate visualizations (at least 3)\n",
    "    generate_visualizations(cleaned_df)\n",
    "    \n",
    "    # 6. Generate tags from free text\n",
    "    tagged_df, tag_columns = generate_tags_from_text(cleaned_df)\n",
    "    \n",
    "    # 7. Overall synthesis and key takeaways\n",
    "    generate_synthesis(df, tagged_df, cleaning_steps, tag_columns)\n",
    "    \n",
    "    # 8. Save cleaned data\n",
    "    save_cleaned_data(tagged_df, OUTPUT_FILE)\n",
    "    \n",
    "    # Final summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"✓ ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Original shape: {df.shape}\")\n",
    "    print(f\"Final shape: {tagged_df.shape}\")\n",
    "    print(f\"\\nGenerated files:\")\n",
    "    print(\"  - steering_wheel_analysis.png\")\n",
    "    print(\"  - detailed_analysis.png\")\n",
    "    print(\"  - issue_tags_analysis.png\")\n",
    "    print(f\"  - {OUTPUT_FILE}\")\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2cd7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
